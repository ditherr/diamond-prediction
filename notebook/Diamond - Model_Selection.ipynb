{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1QoQQN-GWga"
      },
      "source": [
        "# **ðŸ’ŽDiamond Price PredictionðŸ’Ž**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Development\n",
        "**Steps involved in Model Building**:\n",
        "- Setting up features and target\n",
        "- Build a pipeline of standard scalar and model for five different regressors.\n",
        "- Fit all the models on training data\n",
        "- Get mean of cross-validation on the training set for all the models for negative root mean square error\n",
        "- Pick the model with the best cross-validation score\n",
        "- Fit the best model on the training set and get"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M0hw7R2KPT4G"
      },
      "outputs": [],
      "source": [
        "# Basic Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Modelling\n",
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Metric and Model Selection\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8vq8KmhfaE9"
      },
      "source": [
        "### Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "rouc66Eom9Dc"
      },
      "outputs": [],
      "source": [
        "# Make copy to avoid changing original data\n",
        "data_label = pd.read_csv('./data/diamonds-clean.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "P5Z0_51AlLic"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data_label.drop(['price'], axis=1)\n",
        "y = data_label['price']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrrrWtoglc29",
        "outputId": "f63d218d-efc1-48f3-9da3-29c2ccd2467d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total # of sample in whole dataset: 51938\n",
            "Total # of sample in train dataset: 41550\n",
            "Total # of sample in test dataset: 10388\n"
          ]
        }
      ],
      "source": [
        "print(f'Total # of sample in whole dataset: {len(X)}')\n",
        "print(f'Total # of sample in train dataset: {len(X_train)}')\n",
        "print(f'Total # of sample in test dataset: {len(X_test)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dUY5iM-fVj8"
      },
      "source": [
        "### Encoding & Standardization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "U85Tbvy8egYL",
        "outputId": "d385c802-6684-453d-d0c8-786b7213b66e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;OneHotEncoder&#x27;, OneHotEncoder(drop=&#x27;first&#x27;),\n",
              "                                 Index([&#x27;cut&#x27;, &#x27;color&#x27;, &#x27;clarity&#x27;], dtype=&#x27;object&#x27;)),\n",
              "                                (&#x27;StandardScaler&#x27;, StandardScaler(),\n",
              "                                 Index([&#x27;carat&#x27;, &#x27;depth&#x27;, &#x27;table&#x27;, &#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;], dtype=&#x27;object&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;OneHotEncoder&#x27;, OneHotEncoder(drop=&#x27;first&#x27;),\n",
              "                                 Index([&#x27;cut&#x27;, &#x27;color&#x27;, &#x27;clarity&#x27;], dtype=&#x27;object&#x27;)),\n",
              "                                (&#x27;StandardScaler&#x27;, StandardScaler(),\n",
              "                                 Index([&#x27;carat&#x27;, &#x27;depth&#x27;, &#x27;table&#x27;, &#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;], dtype=&#x27;object&#x27;))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;cut&#x27;, &#x27;color&#x27;, &#x27;clarity&#x27;], dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;carat&#x27;, &#x27;depth&#x27;, &#x27;table&#x27;, &#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;], dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "ColumnTransformer(transformers=[('OneHotEncoder', OneHotEncoder(drop='first'),\n",
              "                                 Index(['cut', 'color', 'clarity'], dtype='object')),\n",
              "                                ('StandardScaler', StandardScaler(),\n",
              "                                 Index(['carat', 'depth', 'table', 'x', 'y', 'z'], dtype='object'))])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create Column Transformer with 3 types of transformers\n",
        "num_features = X.select_dtypes(exclude=\"category\").columns\n",
        "cat_features = X.select_dtypes(include=\"category\").columns\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "numeric_transformer = StandardScaler()\n",
        "oh_transformer = OneHotEncoder(drop='first')\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    [\n",
        "        (\"OneHotEncoder\", oh_transformer, cat_features),\n",
        "        (\"StandardScaler\", numeric_transformer, num_features),\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A0ayDKOjL5S"
      },
      "source": [
        "### **Find the Best Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBzciyZOjX7D"
      },
      "source": [
        "**Create the Evaluate Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "2wHyLduSmK-p"
      },
      "outputs": [],
      "source": [
        "# Define the evaluation function\n",
        "def evaluate_model(true, predicted):\n",
        "    mae = mean_absolute_error(true, predicted)\n",
        "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
        "    r2 = r2_score(true, predicted)\n",
        "    return mae, rmse, r2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJqvrnbem1wg"
      },
      "source": [
        "**Crete the Helper Function for training and evaluating models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "woC8tZ8ymFX8"
      },
      "outputs": [],
      "source": [
        "# Helper function for training and evaluating models\n",
        "def run_model(model_name, pipeline, param_grid):\n",
        "    # Setup GridSearchCV\n",
        "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
        "\n",
        "    # Fit model\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best model\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    # Evaluate on training set\n",
        "    y_train_pred = best_model.predict(X_train)\n",
        "    train_mae, train_rmse, train_r2 = evaluate_model(y_train, y_train_pred)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    y_test_pred = best_model.predict(X_test)\n",
        "    test_mae, test_rmse, test_r2 = evaluate_model(y_test, y_test_pred)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"{model_name} Best Hyperparameters: {grid_search.best_params_}\")\n",
        "    print(f\"Training set performance:\\n - MAE: {train_mae:.4f}\\n - RMSE: {train_rmse:.4f}\\n - R2: {train_r2:.4f}\")\n",
        "    print(f\"Test set performance:\\n - MAE: {test_mae:.4f}\\n - RMSE: {test_rmse:.4f}\\n - R2: {test_r2:.4f}\")\n",
        "    print('=' * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dceuB-gIm66W"
      },
      "source": [
        "**Define the Model and Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "WZBLTHs8mCli"
      },
      "outputs": [],
      "source": [
        "# Define the models and hyperparameters for each model\n",
        "models = {\n",
        "    \"Linear Regression\": {\n",
        "        \"model\": LinearRegression(),\n",
        "        \"params\": {\n",
        "            \"model__fit_intercept\": [True, False]\n",
        "        }\n",
        "    },\n",
        "    \"Lasso\": {\n",
        "        \"model\": Lasso(),\n",
        "        \"params\": {\n",
        "            \"model__alpha\": [0.1, 1.0, 10.0]\n",
        "        }\n",
        "    },\n",
        "    \"K-Neighbors Regressor\": {\n",
        "        \"model\": KNeighborsRegressor(),\n",
        "        \"params\": {\n",
        "            \"model__n_neighbors\": [3, 5, 7]\n",
        "        }\n",
        "    },\n",
        "    \"Random Forest Regressor\": {\n",
        "        \"model\": RandomForestRegressor(),\n",
        "        \"params\": {\n",
        "            \"model__n_estimators\": [50, 100],\n",
        "            \"model__max_depth\": [None, 5, 10],\n",
        "            \"model__max_features\": [\"auto\", 5, 7, 8],\n",
        "        }\n",
        "    },\n",
        "    \"XGBRegressor\": {\n",
        "        \"model\": XGBRegressor(),\n",
        "        \"params\": {\n",
        "            \"model__n_estimators\": [50, 100],\n",
        "            \"model__learning_rate\": [0.01, 0.1, 0.3]\n",
        "        }\n",
        "    },\n",
        "    \"CatBoost\": {\n",
        "        \"model\": CatBoostRegressor(verbose=False),\n",
        "        \"params\": {\n",
        "            \"model__depth\": [6, 8],\n",
        "            \"model__learning_rate\": [0.01, 0.1],\n",
        "            \"model__iterations\": [100, 200]\n",
        "        }\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lgmrYk1dmIZ1",
        "outputId": "84dbd982-9b35-42c1-b69c-ec380de5ee13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear Regression Best Hyperparameters: {'model__fit_intercept': True}\n",
            "Training set performance:\n",
            " - MAE: 694.2722\n",
            " - RMSE: 1041.0746\n",
            " - R2: 0.9294\n",
            "Test set performance:\n",
            " - MAE: 699.6570\n",
            " - RMSE: 1050.4327\n",
            " - R2: 0.9278\n",
            "==================================================\n",
            "Lasso Best Hyperparameters: {'model__alpha': 0.1}\n",
            "Training set performance:\n",
            " - MAE: 693.3417\n",
            " - RMSE: 1041.2171\n",
            " - R2: 0.9294\n",
            "Test set performance:\n",
            " - MAE: 698.7602\n",
            " - RMSE: 1050.5554\n",
            " - R2: 0.9278\n",
            "==================================================\n",
            "K-Neighbors Regressor Best Hyperparameters: {'model__n_neighbors': 5}\n",
            "Training set performance:\n",
            " - MAE: 324.3995\n",
            " - RMSE: 638.0807\n",
            " - R2: 0.9735\n",
            "Test set performance:\n",
            " - MAE: 409.0384\n",
            " - RMSE: 784.2999\n",
            " - R2: 0.9597\n",
            "==================================================\n",
            "Random Forest Regressor Best Hyperparameters: {'model__max_depth': None, 'model__max_features': 8, 'model__n_estimators': 100}\n",
            "Training set performance:\n",
            " - MAE: 107.7902\n",
            " - RMSE: 227.1172\n",
            " - R2: 0.9966\n",
            "Test set performance:\n",
            " - MAE: 296.1412\n",
            " - RMSE: 619.8238\n",
            " - R2: 0.9749\n",
            "==================================================\n",
            "XGBRegressor Best Hyperparameters: {'model__learning_rate': 0.3, 'model__n_estimators': 100}\n",
            "Training set performance:\n",
            " - MAE: 231.3149\n",
            " - RMSE: 416.4545\n",
            " - R2: 0.9887\n",
            "Test set performance:\n",
            " - MAE: 287.4817\n",
            " - RMSE: 552.4762\n",
            " - R2: 0.9800\n",
            "==================================================\n",
            "CatBoost Best Hyperparameters: {'model__depth': 8, 'model__iterations': 200, 'model__learning_rate': 0.1}\n",
            "Training set performance:\n",
            " - MAE: 282.3955\n",
            " - RMSE: 517.2944\n",
            " - R2: 0.9826\n",
            "Test set performance:\n",
            " - MAE: 306.2577\n",
            " - RMSE: 575.6542\n",
            " - R2: 0.9783\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Run the models\n",
        "for model_name, model_dict in models.items():\n",
        "    model = model_dict['model']\n",
        "    param_grid = model_dict['params']\n",
        "\n",
        "    # Create pipeline\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),  # Add your ColumnTransformer here for preprocessing\n",
        "        ('model', model)\n",
        "    ])\n",
        "\n",
        "    # Train and evaluate\n",
        "    run_model(model_name, pipeline, param_grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iVQv0DauzDQ"
      },
      "source": [
        "Note:\n",
        "\n",
        "Based on the result, there are two models that i want to observe and consider between **Random Forest Regression** and **XGBoost Regression**\n",
        "\n",
        "- **`RandomForestRegressor`** âž¡ Random Forest *has excellent training performance, but the gap between training and test performance suggests some potential overfitting*. The *`RÂ²` on the test set is slightly lower* compared to XGBoost, and *the `RMSE` is higher*.\n",
        "\n",
        "- **`XGBoostRegressor`** âž¡ XGBoost *has slightly worse performance on the training set but does better on the test set* compared to Random Forest. The *`RMSE` is lower on the test set*, and the *`RÂ²` score is higher*, indicating **better generalization**.\n",
        "\n",
        "Based on the observation, i will choose the **`XGBoost` as our final model.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs-QQNw-pxUb"
      },
      "source": [
        "### **Save the Best Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACxw6nd9uydg",
        "outputId": "b56f2a7b-d60e-47d0-9749-32e5e90d51be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and preprocessor saved as final_model_pipeline.pkl\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming `preprocessor` is the preprocessing pipeline and `best_model` is the trained XGBRegressor\n",
        "final_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', XGBRegressor(learning_rate=0.3, n_estimators=100))  # Best hyperparameters\n",
        "])\n",
        "\n",
        "# Fit the pipeline with the full training data\n",
        "final_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Save the pipeline (model + preprocessor) to a .pkl file\n",
        "with open('./data/final_model_pipeline.pkl', 'wb') as f:\n",
        "    pickle.dump(final_pipeline, f)\n",
        "\n",
        "print(\"Model and preprocessor saved as final_model_pipeline.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxcCQ9P0w0pj"
      },
      "source": [
        "**Test to new data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjMmmm1Tw2cu",
        "outputId": "64c6c403-dd33-4714-abf5-b181972675fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted values: [ 314.3677   368.07376 2811.642  ]\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Load the saved pipeline\n",
        "with open('final_model_pipeline.pkl', 'rb') as f:\n",
        "    loaded_pipeline = pickle.load(f)\n",
        "\n",
        "# Assuming `new_data` is the new input data (as a DataFrame)\n",
        "new_data = pd.DataFrame({'carat': [0.23, 0.31, 0.75],\n",
        "                         'cut': ['Ideal', 'Good', 'Ideal'],\n",
        "                         'color': ['E', 'J', 'D'],\n",
        "                         'clarity': ['SI2', 'SI2', 'SI2'],\n",
        "                         'depth': [61.5, 63.3, 62.2],\n",
        "                         'table': [55.0, 58.0, 55.0],\n",
        "                         'x': [3.95, 4.34, 5.83],\n",
        "                         'y': [3.98, 4.35, 5.87],\n",
        "                         'z': [2.43, 2.75, 3.64],\n",
        "                         })\n",
        "\n",
        "# Predict using the loaded pipeline\n",
        "predictions = loaded_pipeline.predict(new_data)\n",
        "\n",
        "# Print the predictions\n",
        "print(\"Predicted values:\", predictions)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
